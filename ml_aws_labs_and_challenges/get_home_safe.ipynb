{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get home safe\n",
    "\n",
    "---\n",
    "\n",
    "Your problem is to reach the top of the mountain where you reside. You just realized that your car is under powered to climb. Luckily there's another mountain on the opposite side which can be used to gain momentum, and launch the car to the peak. You will use your Machine Learning approach to solve this problem.\n",
    "\n",
    "**Mountain Car** is a classic control Reinforcement Learning problem that was first introduced by A. Moore in 1991 [1].\n",
    "\n",
    "You will use AI Gym’s MountainCarContinuous-v0 variant to validate your theory.\n",
    "\n",
    "**Details**\n",
    "\n",
    "* **State:** Car’s horizontal position and velocity (can be negative).\n",
    "* **Action:** Magnitude of push (if negative push to left, if positive push to right).\n",
    "* **Reward:** +100 for reaching top of the right hand side mountain, minus the squared sum of actions from start to end.\n",
    "\n",
    "<img src=\"./successful_policy.gif\">\n",
    "\n",
    "[1] A. Moore, Efficient Memory-Based Learning for Robot Control, PhD thesis, University of Cambridge, November 1990.\n",
    "\n",
    "\n",
    "*This notebook is tested using ml.t3.medium notebook instance.*\n",
    "\n",
    "*To keep things simple, the amount of time in each episode from Open AI Gym’s default of 200 environment steps is extended to 10,000 steps.*\n",
    "\n",
    "*This notebook is based on the sample notebook available in https://github.com/aws/amazon-sagemaker-examples/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Pre-requisites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Imports\n",
    "\n",
    "To get started, import the Python libraries you need, set up the environment with a few prerequisites for permissions and configurations.\n",
    "\n",
    "#### Code Cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:17:10.806616Z",
     "iopub.status.busy": "2025-06-14T14:17:10.806226Z",
     "iopub.status.idle": "2025-06-14T14:17:13.390465Z",
     "shell.execute_reply": "2025-06-14T14:17:13.389628Z",
     "shell.execute_reply.started": "2025-06-14T14:17:10.806586Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sys.path.append(\"common\")\n",
    "from misc import get_execution_role, wait_for_s3_object\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set up the S3 bucket and define the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the linkage and authentication to the S3 bucket that you want to use for checkpoint and the metadata. \n",
    "\n",
    "#### Code Cell 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:19:52.394723Z",
     "iopub.status.busy": "2025-06-14T14:19:52.393997Z",
     "iopub.status.idle": "2025-06-14T14:19:52.598768Z",
     "shell.execute_reply": "2025-06-14T14:19:52.597645Z",
     "shell.execute_reply.started": "2025-06-14T14:19:52.394690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket path: s3://get-home-safe-216537167580-50a65120/\n"
     ]
    }
   ],
   "source": [
    "# Get your bucket name with prifix 'get-home-safe-'\n",
    "client = boto3.client('s3')\n",
    "response = client.list_buckets()\n",
    "\n",
    "for item in response.get('Buckets'):\n",
    "    if re.search('get-home-safe-', item.get('Name')):\n",
    "        s3_bucket = item.get('Name')\n",
    "\n",
    "s3_output_path = \"s3://{}/\".format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for the job prefix for the training jobs.\n",
    "\n",
    "#### Code Cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:20:05.783084Z",
     "iopub.status.busy": "2025-06-14T14:20:05.782704Z",
     "iopub.status.idle": "2025-06-14T14:20:05.786802Z",
     "shell.execute_reply": "2025-06-14T14:20:05.785905Z",
     "shell.execute_reply.started": "2025-06-14T14:20:05.783061Z"
    }
   },
   "outputs": [],
   "source": [
    "job_name_prefix = \"get-home-safe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create an IAM role\n",
    "\n",
    "Get the IAM role using `role = sagemaker.get_execution_role()`. \n",
    "\n",
    "`get_execution_role()` retrieves the IAM role from the notebook instance. You can then pass the role to run different tasks.\n",
    "\n",
    "#### Code Cell 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:20:08.462237Z",
     "iopub.status.busy": "2025-06-14T14:20:08.461925Z",
     "iopub.status.idle": "2025-06-14T14:20:08.556828Z",
     "shell.execute_reply": "2025-06-14T14:20:08.555816Z",
     "shell.execute_reply.started": "2025-06-14T14:20:08.462211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using IAM role arn: arn:aws:iam::216537167580:role/sagemaker_studio_role\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(\"Using IAM role arn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Review the relevant functions and wrapper files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Review patient_envs.py\n",
    "\n",
    "A `src/patient_envs.py` file is created for the modified environments. Since you are using the Open AI Gym environment and wrappers, you need a function that takes the classic control environments `Continuous_MountainCarEnv` and wraps it with a `TimeLimit` that specifies the `max_episode_steps` to 10,000.\n",
    "\n",
    "#### Code Cell 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:20:12.010523Z",
     "iopub.status.busy": "2025-06-14T14:20:12.009864Z",
     "iopub.status.idle": "2025-06-14T14:20:12.997858Z",
     "shell.execute_reply": "2025-06-14T14:20:12.996770Z",
     "shell.execute_reply.started": "2025-06-14T14:20:12.010491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mgym\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36menvs\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mclassic_control\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcontinuous_mountain_car\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m Continuous_MountainCarEnv\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mgym\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mwrappers\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtime_limit\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m TimeLimit\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mPatientContinuousMountainCar\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
      "    env = Continuous_MountainCarEnv()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m TimeLimit(env, max_episode_steps=\u001b[34m10000\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/patient_envs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Review the preset-mountain-car-continuous-clipped-ppo.py file \n",
    "\n",
    "The presets that configure the RL training jobs are defined in the \"preset-mountain-car-continuous-clipped-ppo.py\" file which is also uploaded on the /src directory. Also see \"preset-mountain-car-dqn.py\" for the discrete environment case. Using the preset file, you can define agent parameters to select the specific agent algorithm. You can also set the environment parameters, define the schedule and visualization parameters, and define the graph manager. The schedule presets will define the number of heat up steps, periodic evaluation steps, training steps between evaluations.\n",
    "\n",
    "These can be overridden at runtime by specifying the RLCOACH_PRESET hyperparameter. Additionally, it can be used to define custom hyperparameters.\n",
    "\n",
    "#### Code Cell 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:20:22.599884Z",
     "iopub.status.busy": "2025-06-14T14:20:22.599144Z",
     "iopub.status.idle": "2025-06-14T14:20:23.542513Z",
     "shell.execute_reply": "2025-06-14T14:20:23.541531Z",
     "shell.execute_reply.started": "2025-06-14T14:20:22.599848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36magents\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mclipped_ppo_agent\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m ClippedPPOAgentParameters\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36marchitectures\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlayers\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m Dense\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mbase_parameters\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m PresetValidationParameters, VisualizationParameters\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcore_types\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m (\u001b[37m\u001b[39;49;00m\n",
      "    EnvironmentEpisodes,\u001b[37m\u001b[39;49;00m\n",
      "    EnvironmentSteps,\u001b[37m\u001b[39;49;00m\n",
      "    MaxDumpFilter,\u001b[37m\u001b[39;49;00m\n",
      "    RunPhase,\u001b[37m\u001b[39;49;00m\n",
      "    SelectedPhaseOnlyDumpFilter,\u001b[37m\u001b[39;49;00m\n",
      "    TrainingSteps,\u001b[37m\u001b[39;49;00m\n",
      ")\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36menvironments\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mgym_environment\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m GymVectorEnvironment\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexploration_policies\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36me_greedy\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m EGreedyParameters\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfilters\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mobservation\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mobservation_normalization_filter\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m (\u001b[37m\u001b[39;49;00m\n",
      "    ObservationNormalizationFilter,\u001b[37m\u001b[39;49;00m\n",
      ")\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mgraph_managers\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mbasic_rl_graph_manager\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m BasicRLGraphManager\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mgraph_managers\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mgraph_manager\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m ScheduleParameters\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mschedules\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m LinearSchedule\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m####################\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Graph Scheduling #\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m####################\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "schedule_params = ScheduleParameters()\u001b[37m\u001b[39;49;00m\n",
      "schedule_params.improve_steps = EnvironmentEpisodes(\u001b[34m100\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "schedule_params.steps_between_evaluation_periods = EnvironmentEpisodes(\u001b[34m10\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "schedule_params.evaluation_steps = EnvironmentEpisodes(\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "schedule_params.heatup_steps = EnvironmentEpisodes(\u001b[34m10\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#########\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Agent #\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#########\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params = ClippedPPOAgentParameters()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m\"\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].learning_rate = \u001b[34m0.001\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m\"\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].input_embedders_parameters[\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m\"\u001b[39;49;00m\u001b[33mobservation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "].activation_function = \u001b[33m\"\u001b[39;49;00m\u001b[33mtanh\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m\"\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].input_embedders_parameters[\u001b[33m\"\u001b[39;49;00m\u001b[33mobservation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].scheme = [Dense(\u001b[34m32\u001b[39;49;00m)]\u001b[37m\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m\"\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].middleware_parameters.scheme = [Dense(\u001b[34m32\u001b[39;49;00m)]\u001b[37m\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m\"\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].middleware_parameters.activation_function = \u001b[33m\"\u001b[39;49;00m\u001b[33mtanh\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m\"\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].batch_size = \u001b[34m256\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m\"\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].optimizer_epsilon = \u001b[34m1e-5\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m\"\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].adam_optimizer_beta2 = \u001b[34m0.999\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "agent_params.algorithm.clip_likelihood_ratio_using_epsilon = \u001b[34m0.3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.algorithm.clipping_decay_schedule = LinearSchedule(\u001b[34m0.5\u001b[39;49;00m, \u001b[34m0.1\u001b[39;49;00m, \u001b[34m10000\u001b[39;49;00m * \u001b[34m50\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "agent_params.algorithm.beta_entropy = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.algorithm.gae_lambda = \u001b[34m0.95\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.algorithm.discount = \u001b[34m0.999\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.algorithm.estimate_state_value_using_gae = \u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "agent_params.algorithm.num_steps_between_copying_online_weights_to_target = EnvironmentEpisodes(\u001b[34m10\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "agent_params.algorithm.num_episodes_in_experience_replay = \u001b[34m100\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.algorithm.num_consecutive_playing_steps = EnvironmentEpisodes(\u001b[34m10\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "agent_params.algorithm.optimization_epochs = \u001b[34m10\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "agent_params.pre_network_filter.add_observation_filter(\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m\"\u001b[39;49;00m\u001b[33mobservation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m\"\u001b[39;49;00m\u001b[33mnormalize_observation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    ObservationNormalizationFilter(name=\u001b[33m\"\u001b[39;49;00m\u001b[33mnormalize_observation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      ")\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m###############\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Environment #\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m###############\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "env_params = GymVectorEnvironment(level=\u001b[33m\"\u001b[39;49;00m\u001b[33mpatient_envs:PatientContinuousMountainCar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#################\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Visualization #\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#################\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "vis_params = VisualizationParameters()\u001b[37m\u001b[39;49;00m\n",
      "vis_params.dump_gifs = \u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "vis_params.video_dump_filters = [SelectedPhaseOnlyDumpFilter(RunPhase.TEST), MaxDumpFilter()]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m########\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Test #\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m########\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "preset_validation_params = PresetValidationParameters()\u001b[37m\u001b[39;49;00m\n",
      "preset_validation_params.test = \u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "preset_validation_params.min_reward_threshold = \u001b[34m150\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "preset_validation_params.max_episodes_to_achieve_reward = \u001b[34m250\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "graph_manager = BasicRLGraphManager(\u001b[37m\u001b[39;49;00m\n",
      "    agent_params=agent_params,\u001b[37m\u001b[39;49;00m\n",
      "    env_params=env_params,\u001b[37m\u001b[39;49;00m\n",
      "    schedule_params=schedule_params,\u001b[37m\u001b[39;49;00m\n",
      "    vis_params=vis_params,\u001b[37m\u001b[39;49;00m\n",
      "    preset_validation_params=preset_validation_params,\u001b[37m\u001b[39;49;00m\n",
      ")\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/preset-mountain-car-continuous-clipped-ppo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Review the train-coach.py file\n",
    "\n",
    "The training code is written in the file “train-coach.py” which is uploaded in the /src directory. \n",
    "We create a custom `SageMakerCoachPresetLauncher` which sets the default preset, maps and ties hyperparameters.\n",
    "\n",
    "#### Code Cell 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:20:27.799354Z",
     "iopub.status.busy": "2025-06-14T14:20:27.798838Z",
     "iopub.status.idle": "2025-06-14T14:20:28.792659Z",
     "shell.execute_reply": "2025-06-14T14:20:28.791364Z",
     "shell.execute_reply.started": "2025-06-14T14:20:27.799320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36msagemaker_rl\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcoach_launcher\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m SageMakerCoachPresetLauncher\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[32mMyLauncher\u001b[39;49;00m(SageMakerCoachPresetLauncher):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mdefault_preset_name\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[33m\"\"\"This points to a .py file that configures everything about the RL job.\u001b[39;49;00m\n",
      "\u001b[33m        It can be overridden at runtime by specifying the RLCOACH_PRESET hyperparameter.\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mpreset-mountaincarcontinuous-clippedppo.py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mmap_hyperparameter\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, name, value):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[33m\"\"\"Here we configure some shortcut names for hyperparameters that we expect to use frequently.\u001b[39;49;00m\n",
      "\u001b[33m        Essentially anything in the preset file can be overridden through a hyperparameter with a name\u001b[39;49;00m\n",
      "\u001b[33m        like \"rl.agent_params.algorithm.etc\".\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# maps from alias (key) to fully qualified coach parameter (value)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        mapping = {\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mevaluation_freq_env_steps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.steps_between_evaluation_periods:EnvironmentSteps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mevaluation_episodes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.evaluation_steps:EnvironmentEpisodes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mimprove_steps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.improve_steps:EnvironmentSteps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mdiscount\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.agent_params.algorithm.discount\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mgae_lambda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.agent_params.algorithm.gae_lambda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mtraining_freq_env_steps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.agent_params.algorithm.num_consecutive_playing_steps:EnvironmentSteps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mtraining_learning_rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.agent_params.network_wrappers.main.learning_rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mtraining_batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.agent_params.network_wrappers.main.batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mtraining_epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.agent_params.algorithm.optimization_epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        }\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m name \u001b[35min\u001b[39;49;00m mapping:\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.apply_hyperparameter(mapping[name], value)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36msuper\u001b[39;49;00m().map_hyperparameter(name, value)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mget_config_args\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, parser):\u001b[37m\u001b[39;49;00m\n",
      "        args = \u001b[36msuper\u001b[39;49;00m().get_config_args(parser)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Above line creates `self.hyperparameters` which is a collection of hyperparameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# that are to be added to graph manager when it's created. At this stage they are\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# fully qualified names since already passed through `map_hyperparameter`.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Keeps target network the same for all epochs of a single 'policy training' stage.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        src_hp = \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.agent_params.algorithm.num_consecutive_playing_steps:EnvironmentSteps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        target_hp = \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.agent_params.algorithm.num_steps_between_copying_online_weights_to_target:EnvironmentSteps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.hyperparameters.hp_dict.get(src_hp, \u001b[34mFalse\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "            src_val = \u001b[36mint\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.hyperparameters.hp_dict[src_hp])\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.hyperparameters.hp_dict[target_hp] = src_val\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Evaluate after each 'policy training' stage\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        src_hp = \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.agent_params.algorithm.num_consecutive_playing_steps:EnvironmentSteps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        target_hp = \u001b[33m\"\u001b[39;49;00m\u001b[33mrl.steps_between_evaluation_periods:EnvironmentSteps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.hyperparameters.hp_dict.get(src_hp, \u001b[34mFalse\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "            src_val = \u001b[36mint\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.hyperparameters.hp_dict[src_hp])\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.hyperparameters.hp_dict[target_hp] = src_val\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m args\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    MyLauncher.train_main()\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/train-coach.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Train the RL model using the Python SDK Script mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When using SageMaker for training, you can select a GPU or CPU instance. The RLEstimator is used for training RL jobs. \n",
    "\n",
    "1. Specify the source directory where the environment, presets and training code is uploaded.\n",
    "2. Specify the entry point as the training code \n",
    "3. Specify the choice of RL toolkit and framework. This automatically resolves to the ECR path for the RL Container. \n",
    "4. Define the training parameters such as the instance count, job name, S3 path for output and job name. \n",
    "5. Specify the hyperparameters for the RL agent algorithm. The RLCOACH_PRESET can be used to specify the RL agent algorithm you want to use. \n",
    "6. Define the metrics definitions that you are interested in capturing in your logs. These can also be visualized in CloudWatch and SageMaker Notebooks. \n",
    "\n",
    "You are using variant of Proximal Policy Optimization (PPO) called Clipped PPO, which removes the need for complex KL divergence calculations.\n",
    "\n",
    "#### Code Cell 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:20:32.700598Z",
     "iopub.status.busy": "2025-06-14T14:20:32.700091Z",
     "iopub.status.idle": "2025-06-14T14:29:27.194790Z",
     "shell.execute_reply": "2025-06-14T14:29:27.193666Z",
     "shell.execute_reply.started": "2025-06-14T14:20:32.700563Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker:Creating training-job with name: get-home-safe-2025-06-14-14-20-32-741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-14 14:20:37 Starting - Starting the training job...\n",
      "2025-06-14 14:20:50 Starting - Preparing the instances for training...\n",
      "2025-06-14 14:21:32 Downloading - Downloading the training image...\n",
      "2025-06-14 14:21:47 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2025-06-14 14:21:56,728 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2025-06-14 14:21:56,732 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-06-14 14:21:56,747 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_MODULE_DIR': 's3://get-home-safe-216537167580-50a65120/get-home-safe-2025-06-14-14-20-32-741/source/sourcedir.tar.gz', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}', 'SM_CURRENT_HOST': 'algo-1', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_HP_SAVE_MODEL': '1', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_HP_EVALUATION_EPISODES': '3', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HP_IMPROVE_STEPS': '100000', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"RLCOACH_PRESET\":\"preset-mountain-car-continuous-clipped-ppo\",\"discount\":0.995,\"evaluation_episodes\":3,\"gae_lambda\":0.997,\"improve_steps\":100000,\"save_model\":1,\"training_batch_size\":256,\"training_epochs\":10,\"training_freq_env_steps\":75000,\"training_learning_rate\":0.005},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"get-home-safe-2025-06-14-14-20-32-741\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://get-home-safe-216537167580-50a65120/get-home-safe-2025-06-14-14-20-32-741/source/sourcedir.tar.gz\",\"module_name\":\"train-coach\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train-coach.py\"}', 'SM_NUM_GPUS': '0', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_GAE_LAMBDA': '0.997', 'SM_HP_TRAINING_FREQ_ENV_STEPS': '75000', 'SM_HP_DISCOUNT': '0.995', 'SM_MODULE_NAME': 'train-coach', 'SM_INPUT_DATA_CONFIG': '{}', 'SM_HP_RLCOACH_PRESET': 'preset-mountain-car-continuous-clipped-ppo', 'SM_HP_TRAINING_LEARNING_RATE': '0.005', 'SM_USER_ENTRY_POINT': 'train-coach.py', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_estimator\":\"RLEstimator\"}', 'SM_LOG_LEVEL': '20', 'SM_HOSTS': '[\"algo-1\"]', 'SM_NUM_CPUS': '4', 'SM_HP_TRAINING_EPOCHS': '10', 'SM_HP_TRAINING_BATCH_SIZE': '256', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_HPS': '{\"RLCOACH_PRESET\":\"preset-mountain-car-continuous-clipped-ppo\",\"discount\":0.995,\"evaluation_episodes\":3,\"gae_lambda\":0.997,\"improve_steps\":100000,\"save_model\":1,\"training_batch_size\":256,\"training_epochs\":10,\"training_freq_env_steps\":75000,\"training_learning_rate\":0.005}', 'SM_USER_ARGS': '[\"--RLCOACH_PRESET\",\"preset-mountain-car-continuous-clipped-ppo\",\"--discount\",\"0.995\",\"--evaluation_episodes\",\"3\",\"--gae_lambda\",\"0.997\",\"--improve_steps\",\"100000\",\"--save_model\",\"1\",\"--training_batch_size\",\"256\",\"--training_epochs\",\"10\",\"--training_freq_env_steps\",\"75000\",\"--training_learning_rate\",\"0.005\"]', 'SM_CHANNELS': '[]', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main'}\u001b[0m\n",
      "\u001b[34m2025-06-14 14:21:56,966 sagemaker-containers INFO     Module train-coach does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2025-06-14 14:21:56,967 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2025-06-14 14:21:56,967 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2025-06-14 14:21:56,967 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train-coach\n",
      "  Running setup.py bdist_wheel for train-coach: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train-coach: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nmqx0980/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train-coach\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train-coach\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-coach-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3.4 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2025-06-14 14:21:58,467 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-06-14 14:21:58,485 sagemaker-containers INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"resource_config\": {\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null,\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ],\n",
      "                \"instance_group_name\": \"homogeneousCluster\"\n",
      "            }\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"module_name\": \"train-coach\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"hyperparameters\": {\n",
      "        \"training_epochs\": 10,\n",
      "        \"gae_lambda\": 0.997,\n",
      "        \"training_learning_rate\": 0.005,\n",
      "        \"RLCOACH_PRESET\": \"preset-mountain-car-continuous-clipped-ppo\",\n",
      "        \"training_freq_env_steps\": 75000,\n",
      "        \"improve_steps\": 100000,\n",
      "        \"save_model\": 1,\n",
      "        \"evaluation_episodes\": 3,\n",
      "        \"discount\": 0.995,\n",
      "        \"training_batch_size\": 256\n",
      "    },\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"module_dir\": \"s3://get-home-safe-216537167580-50a65120/get-home-safe-2025-06-14-14-20-32-741/source/sourcedir.tar.gz\",\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"log_level\": 20,\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator\": \"RLEstimator\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train-coach.py\",\n",
      "    \"input_data_config\": {},\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_cpus\": 4,\n",
      "    \"job_name\": \"get-home-safe-2025-06-14-14-20-32-741\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HPS={\"RLCOACH_PRESET\":\"preset-mountain-car-continuous-clipped-ppo\",\"discount\":0.995,\"evaluation_episodes\":3,\"gae_lambda\":0.997,\"improve_steps\":100000,\"save_model\":1,\"training_batch_size\":256,\"training_epochs\":10,\"training_freq_env_steps\":75000,\"training_learning_rate\":0.005}\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"RLCOACH_PRESET\":\"preset-mountain-car-continuous-clipped-ppo\",\"discount\":0.995,\"evaluation_episodes\":3,\"gae_lambda\":0.997,\"improve_steps\":100000,\"save_model\":1,\"training_batch_size\":256,\"training_epochs\":10,\"training_freq_env_steps\":75000,\"training_learning_rate\":0.005},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"get-home-safe-2025-06-14-14-20-32-741\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://get-home-safe-216537167580-50a65120/get-home-safe-2025-06-14-14-20-32-741/source/sourcedir.tar.gz\",\"module_name\":\"train-coach\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train-coach.py\"}\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_HP_GAE_LAMBDA=0.997\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_FREQ_ENV_STEPS=75000\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_BATCH_SIZE=256\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train-coach.py\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_LEARNING_RATE=0.005\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_DISCOUNT=0.995\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--RLCOACH_PRESET\",\"preset-mountain-car-continuous-clipped-ppo\",\"--discount\",\"0.995\",\"--evaluation_episodes\",\"3\",\"--gae_lambda\",\"0.997\",\"--improve_steps\",\"100000\",\"--save_model\",\"1\",\"--training_batch_size\",\"256\",\"--training_epochs\",\"10\",\"--training_freq_env_steps\",\"75000\",\"--training_learning_rate\",\"0.005\"]\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://get-home-safe-216537167580-50a65120/get-home-safe-2025-06-14-14-20-32-741/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_MODEL=1\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HP_IMPROVE_STEPS=100000\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train-coach\u001b[0m\n",
      "\u001b[34mSM_HP_RLCOACH_PRESET=preset-mountain-car-continuous-clipped-ppo\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_EVALUATION_EPISODES=3\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train-coach --RLCOACH_PRESET preset-mountain-car-continuous-clipped-ppo --discount 0.995 --evaluation_episodes 3 --gae_lambda 0.997 --improve_steps 100000 --save_model 1 --training_batch_size 256 --training_epochs 10 --training_freq_env_steps 75000 --training_learning_rate 0.005\u001b[0m\n",
      "\u001b[34m#033[93mWarning: failed to import the following packages - tensorflow#033[0m\u001b[0m\n",
      "\u001b[34mApplying RL hyperparameter rl.agent_params.algorithm.discount=0.995\u001b[0m\n",
      "\u001b[34mApplying RL hyperparameter rl.evaluation_steps:EnvironmentEpisodes=3\u001b[0m\n",
      "\u001b[34mApplying RL hyperparameter rl.agent_params.algorithm.gae_lambda=0.997\u001b[0m\n",
      "\u001b[34mApplying RL hyperparameter rl.improve_steps:EnvironmentSteps=100000\u001b[0m\n",
      "\u001b[34mApplying RL hyperparameter rl.agent_params.network_wrappers.main.batch_size=256\u001b[0m\n",
      "\u001b[34mApplying RL hyperparameter rl.agent_params.algorithm.optimization_epochs=10\u001b[0m\n",
      "\u001b[34mApplying RL hyperparameter rl.agent_params.algorithm.num_consecutive_playing_steps:EnvironmentSteps=75000\u001b[0m\n",
      "\u001b[34mApplying RL hyperparameter rl.agent_params.network_wrappers.main.learning_rate=0.005\u001b[0m\n",
      "\u001b[34mLoading preset preset-mountain-car-continuous-clipped-ppo from /opt/ml/code\u001b[0m\n",
      "\u001b[34m## Creating graph - name: BasicRLGraphManager\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\u001b[0m\n",
      "\u001b[34m## Creating agent - name: agent\u001b[0m\n",
      "\u001b[34mRequested devices [gpu(0)] not available. Default to CPU context.\u001b[0m\n",
      "\u001b[34mRequested devices [gpu(0)] not available. Default to CPU context.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[34m## simple_rl_graph: Starting heatup\u001b[0m\n",
      "\u001b[34mHeatup> Name=main_level/agent, Worker=0, Episode=1, Total reward=-333.77, Steps=10000, Training iteration=0\u001b[0m\n",
      "\u001b[34mHeatup> Name=main_level/agent, Worker=0, Episode=2, Total reward=-332.08, Steps=20000, Training iteration=0\u001b[0m\n",
      "\u001b[34mHeatup> Name=main_level/agent, Worker=0, Episode=3, Total reward=-336.06, Steps=30000, Training iteration=0\u001b[0m\n",
      "\u001b[34mHeatup> Name=main_level/agent, Worker=0, Episode=4, Total reward=-334.27, Steps=40000, Training iteration=0\u001b[0m\n",
      "\u001b[34mHeatup> Name=main_level/agent, Worker=0, Episode=5, Total reward=-334.87, Steps=50000, Training iteration=0\u001b[0m\n",
      "\u001b[34mHeatup> Name=main_level/agent, Worker=0, Episode=6, Total reward=-329.97, Steps=60000, Training iteration=0\u001b[0m\n",
      "\u001b[34mHeatup> Name=main_level/agent, Worker=0, Episode=7, Total reward=-84.18, Steps=65528, Training iteration=0\u001b[0m\n",
      "\u001b[34mHeatup> Name=main_level/agent, Worker=0, Episode=8, Total reward=-330.1, Steps=75528, Training iteration=0\u001b[0m\n",
      "\u001b[34mHeatup> Name=main_level/agent, Worker=0, Episode=9, Total reward=-206.28, Steps=84679, Training iteration=0\u001b[0m\n",
      "\u001b[34mHeatup> Name=main_level/agent, Worker=0, Episode=10, Total reward=-84.93, Steps=90156, Training iteration=0\u001b[0m\n",
      "\u001b[34m## Starting to improve simple_rl_graph task index 0\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/0_Step-1.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/0_Step-1.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/1_Step-8818.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/1_Step-8818.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=11, Total reward=-373.77, Steps=99452, Training iteration=0\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/rl_coach/architectures/mxnet_components/heads/head.py:95: UserWarning: Parameter clippedppolosscontinuous0_kl_coefficient is not used by any computation. Is this intended?\n",
      "  outputs = super(HeadLoss, self).forward(*args)\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.02396070957183838, KL divergence=[0.], Entropy=[0.], training epoch=0, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.023620732128620148, KL divergence=[0.], Entropy=[0.], training epoch=1, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.023548228666186333, KL divergence=[0.], Entropy=[0.], training epoch=2, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.023731157183647156, KL divergence=[0.], Entropy=[0.], training epoch=3, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.023691430687904358, KL divergence=[0.], Entropy=[0.], training epoch=4, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.023575156927108765, KL divergence=[0.], Entropy=[0.], training epoch=5, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.023621302098035812, KL divergence=[0.], Entropy=[0.], training epoch=6, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.02379494719207287, KL divergence=[0.], Entropy=[0.], training epoch=7, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.023600595071911812, KL divergence=[0.], Entropy=[0.], training epoch=8, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.02384197525680065, KL divergence=[0.], Entropy=[0.], training epoch=9, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/2_Step-9296.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/2_Step-9296.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=12, Total reward=63.76, Steps=100081, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=13, Total reward=-3.94, Steps=101819, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=14, Total reward=2.46, Steps=103448, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=15, Total reward=30.17, Steps=104623, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=16, Total reward=45.0, Steps=105597, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=17, Total reward=28.82, Steps=106860, Training iteration=1\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/3_Step-17245.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/3_Step-17245.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=18, Total reward=21.71, Steps=108205, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=19, Total reward=11.13, Steps=109671, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=20, Total reward=8.47, Steps=111198, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=21, Total reward=33.34, Steps=112352, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=22, Total reward=69.76, Steps=112861, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=23, Total reward=31.67, Steps=113972, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=24, Total reward=46.86, Steps=114886, Training iteration=1\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/4_Step-25131.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/4_Step-25131.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=25, Total reward=-23.28, Steps=116962, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=26, Total reward=68.03, Steps=117491, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=27, Total reward=53.98, Steps=118278, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=28, Total reward=58.58, Steps=118977, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=29, Total reward=52.48, Steps=119827, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=30, Total reward=70.27, Steps=120309, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=31, Total reward=21.68, Steps=121685, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=32, Total reward=42.32, Steps=122681, Training iteration=1\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/5_Step-33014.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/5_Step-33014.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=33, Total reward=17.46, Steps=124082, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=34, Total reward=13.55, Steps=125564, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=35, Total reward=55.73, Steps=126324, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=36, Total reward=53.34, Steps=127139, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=37, Total reward=55.88, Steps=127883, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=38, Total reward=13.92, Steps=129378, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=39, Total reward=20.93, Steps=130727, Training iteration=1\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/6_Step-40878.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/6_Step-40878.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=40, Total reward=32.32, Steps=131873, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=41, Total reward=76.51, Steps=132263, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=42, Total reward=42.52, Steps=133262, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=43, Total reward=70.96, Steps=133781, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=44, Total reward=39.38, Steps=134793, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=45, Total reward=30.43, Steps=135946, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=46, Total reward=41.43, Steps=136966, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=47, Total reward=48.55, Steps=137859, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=48, Total reward=77.81, Steps=138258, Training iteration=1\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/7_Step-48675.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/7_Step-48675.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=49, Total reward=45.75, Steps=139200, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=50, Total reward=46.21, Steps=140087, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=51, Total reward=37.91, Steps=141087, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=52, Total reward=49.85, Steps=141943, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=53, Total reward=62.31, Steps=142565, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=54, Total reward=67.34, Steps=143147, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=55, Total reward=47.79, Steps=144051, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=56, Total reward=39.82, Steps=145105, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=57, Total reward=27.06, Steps=146291, Training iteration=1\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/8_Step-56307.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/8_Step-56307.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=58, Total reward=45.8, Steps=147189, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=59, Total reward=-30.44, Steps=149410, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=60, Total reward=62.97, Steps=150028, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=61, Total reward=0.13, Steps=151779, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=62, Total reward=56.7, Steps=152516, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=63, Total reward=8.61, Steps=154009, Training iteration=1\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/9_Step-64174.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/9_Step-64174.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=64, Total reward=53.8, Steps=154808, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=65, Total reward=48.85, Steps=155666, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=66, Total reward=47.97, Steps=156546, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=67, Total reward=56.61, Steps=157326, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=68, Total reward=36.63, Steps=158456, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=69, Total reward=41.43, Steps=159466, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=70, Total reward=23.56, Steps=160737, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=71, Total reward=54.18, Steps=161483, Training iteration=1\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/10_Step-71994.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/10_Step-71994.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=72, Total reward=38.3, Steps=162485, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=73, Total reward=62.41, Steps=163141, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=74, Total reward=55.35, Steps=163891, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=75, Total reward=35.99, Steps=164952, Training iteration=1\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=75, Total reward=92.05, Steps=165156, Training iteration=1\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=75, Total reward=96.99, Steps=165156, Training iteration=1\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=75, Total reward=95.79, Steps=165156, Training iteration=1\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = 94.94\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/11_Step-75001.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/11_Step-75001.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=76, Total reward=14.67, Steps=166599, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=77, Total reward=62.31, Steps=167254, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=78, Total reward=35.15, Steps=168323, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=79, Total reward=62.6, Steps=168966, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=80, Total reward=26.13, Steps=170220, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=81, Total reward=44.11, Steps=171177, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=82, Total reward=77.23, Steps=171559, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=83, Total reward=58.72, Steps=172260, Training iteration=1\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/12_Step-82787.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/12_Step-82787.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=84, Total reward=57.14, Steps=173008, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=85, Total reward=20.71, Steps=174385, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=86, Total reward=57.13, Steps=175116, Training iteration=1\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.004336285404860973, KL divergence=[0.], Entropy=[0.], training epoch=0, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.003700682893395424, KL divergence=[0.], Entropy=[0.], training epoch=1, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.0036333624739199877, KL divergence=[0.], Entropy=[0.], training epoch=2, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.003372236853465438, KL divergence=[0.], Entropy=[0.], training epoch=3, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.0032060618977993727, KL divergence=[0.], Entropy=[0.], training epoch=4, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.0028855225536972284, KL divergence=[0.], Entropy=[0.], training epoch=5, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.0030368496663868427, KL divergence=[0.], Entropy=[0.], training epoch=6, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.0028827895876020193, KL divergence=[0.], Entropy=[0.], training epoch=7, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.002970665693283081, KL divergence=[0.], Entropy=[0.], training epoch=8, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.0030197519809007645, KL divergence=[0.], Entropy=[0.], training epoch=9, learning_rate=0.005\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/13_Step-84960.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/13_Step-84960.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=87, Total reward=33.33, Steps=176270, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=88, Total reward=59.77, Steps=176955, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=89, Total reward=73.07, Steps=177424, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=90, Total reward=38.08, Steps=178522, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=91, Total reward=47.91, Steps=179449, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=92, Total reward=52.59, Steps=180254, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=93, Total reward=45.05, Steps=181209, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=94, Total reward=57.98, Steps=181933, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=95, Total reward=74.68, Steps=182358, Training iteration=2\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/14_Step-92665.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/14_Step-92665.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=96, Total reward=71.37, Steps=182839, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=97, Total reward=74.36, Steps=183278, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=98, Total reward=64.37, Steps=183875, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=99, Total reward=78.91, Steps=184207, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=100, Total reward=81.96, Steps=184530, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=101, Total reward=68.25, Steps=185051, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=102, Total reward=50.54, Steps=185877, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=103, Total reward=71.84, Steps=186346, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=104, Total reward=56.9, Steps=187081, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=105, Total reward=42.19, Steps=188067, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=106, Total reward=52.21, Steps=188882, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=107, Total reward=68.64, Steps=189399, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=108, Total reward=69.85, Steps=189892, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=109, Total reward=71.03, Steps=190406, Training iteration=2\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/15_Step-100250.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/15_Step-100250.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=110, Total reward=51.5, Steps=191225, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=111, Total reward=74.11, Steps=191660, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=112, Total reward=70.57, Steps=192179, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=113, Total reward=58.78, Steps=192908, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=114, Total reward=62.87, Steps=193550, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=115, Total reward=42.24, Steps=194576, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=116, Total reward=57.84, Steps=195303, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=117, Total reward=49.46, Steps=196184, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=118, Total reward=59.94, Steps=196878, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=119, Total reward=58.55, Steps=197590, Training iteration=2\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/16_Step-108081.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/16_Step-108081.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=120, Total reward=52.89, Steps=198420, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=121, Total reward=62.59, Steps=199053, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=122, Total reward=79.16, Steps=199422, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=123, Total reward=54.08, Steps=200241, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=124, Total reward=66.25, Steps=200817, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=125, Total reward=66.28, Steps=201390, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=126, Total reward=62.58, Steps=202044, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=127, Total reward=42.98, Steps=203011, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=128, Total reward=61.53, Steps=203700, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=129, Total reward=75.06, Steps=204133, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=130, Total reward=59.43, Steps=204864, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=131, Total reward=78.06, Steps=205222, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=132, Total reward=64.85, Steps=205818, Training iteration=2\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/17_Step-115662.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/17_Step-115662.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=133, Total reward=58.81, Steps=206502, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=134, Total reward=41.87, Steps=207497, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=135, Total reward=54.22, Steps=208292, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=136, Total reward=69.32, Steps=208855, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=137, Total reward=48.54, Steps=209732, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=138, Total reward=76.78, Steps=210121, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=139, Total reward=53.21, Steps=210931, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=140, Total reward=67.92, Steps=211505, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=141, Total reward=65.48, Steps=212119, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=142, Total reward=63.17, Steps=212740, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=143, Total reward=72.95, Steps=213197, Training iteration=2\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/18_Step-123378.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/18_Step-123378.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=144, Total reward=72.71, Steps=213669, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=145, Total reward=66.17, Steps=214246, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=146, Total reward=42.61, Steps=215199, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=147, Total reward=85.26, Steps=215440, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=148, Total reward=65.79, Steps=216033, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=149, Total reward=37.49, Steps=217125, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=150, Total reward=65.17, Steps=217729, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=151, Total reward=40.35, Steps=218739, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=152, Total reward=75.61, Steps=219157, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=153, Total reward=63.07, Steps=219795, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=154, Total reward=62.9, Steps=220442, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=155, Total reward=58.24, Steps=221187, Training iteration=2\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/19_Step-131079.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/19_Step-131079.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=156, Total reward=35.68, Steps=222293, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=157, Total reward=19.81, Steps=223686, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=158, Total reward=70.49, Steps=224176, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=159, Total reward=61.78, Steps=224836, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=160, Total reward=55.35, Steps=225608, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=161, Total reward=63.22, Steps=226213, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=162, Total reward=61.68, Steps=226867, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=163, Total reward=51.2, Steps=227724, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=164, Total reward=50.16, Steps=228587, Training iteration=2\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/20_Step-138869.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/20_Step-138869.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=165, Total reward=67.37, Steps=229148, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=166, Total reward=49.17, Steps=229997, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=167, Total reward=56.91, Steps=230754, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=168, Total reward=66.8, Steps=231330, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=169, Total reward=51.16, Steps=232167, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=170, Total reward=62.08, Steps=232853, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=171, Total reward=50.24, Steps=233716, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=172, Total reward=52.61, Steps=234559, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=173, Total reward=50.3, Steps=235414, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=174, Total reward=48.19, Steps=236304, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=175, Total reward=80.99, Steps=236622, Training iteration=2\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/21_Step-146509.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/21_Step-146509.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=176, Total reward=65.96, Steps=237221, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=177, Total reward=62.48, Steps=237854, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=178, Total reward=72.6, Steps=238332, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=179, Total reward=72.88, Steps=238798, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=180, Total reward=46.46, Steps=239725, Training iteration=2\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=180, Total reward=97.61, Steps=240156, Training iteration=2\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=180, Total reward=98.06, Steps=240156, Training iteration=2\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=180, Total reward=98.01, Steps=240156, Training iteration=2\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = 97.89\u001b[0m\n",
      "\u001b[34mONNX correction applied to continuous PPO agent.\u001b[0m\n",
      "\u001b[34m2025-06-14 14:28:54,069 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-06-14 14:29:12 Uploading - Uploading generated training model\n",
      "2025-06-14 14:29:12 Completed - Training job completed\n",
      "Training seconds: 481\n",
      "Billable seconds: 481\n"
     ]
    }
   ],
   "source": [
    "# Define the instance type and epochs\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "epochs = 10\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Define the training jobs parameters and hyper parameters.\n",
    "estimator = RLEstimator(\n",
    "    entry_point=\"train-coach.py\",\n",
    "    source_dir=\"src\",\n",
    "    dependencies=[\"common/sagemaker_rl\"],\n",
    "    toolkit=RLToolkit.COACH,\n",
    "    toolkit_version=\"0.11.0\",\n",
    "    framework=RLFramework.MXNET,\n",
    "    role=role,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=s3_output_path,\n",
    "    base_job_name=job_name_prefix,\n",
    "    hyperparameters={\n",
    "        \"RLCOACH_PRESET\": \"preset-mountain-car-continuous-clipped-ppo\",\n",
    "        \"discount\": 0.995,\n",
    "        \"gae_lambda\": 0.997,\n",
    "        \"evaluation_episodes\": 3,\n",
    "        \"improve_steps\": 100000,\n",
    "        \"training_freq_env_steps\": 75000,\n",
    "        \"training_learning_rate\": learning_rate,\n",
    "        \"training_batch_size\": 256,\n",
    "        \"training_epochs\": epochs,\n",
    "        \"save_model\": 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Store intermediate training output and model checkpoints \n",
    "\n",
    "The output from the training job above is stored on S3. The intermediate folder contains gifs and metadata of the training.\n",
    "\n",
    "#### Code Cell 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:30:14.939046Z",
     "iopub.status.busy": "2025-06-14T14:30:14.938467Z",
     "iopub.status.idle": "2025-06-14T14:30:14.948446Z",
     "shell.execute_reply": "2025-06-14T14:30:14.947376Z",
     "shell.execute_reply.started": "2025-06-14T14:30:14.939014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job name: get-home-safe-2025-06-14-14-20-32-741\n",
      "S3 job path: s3://get-home-safe-216537167580-50a65120/get-home-safe-2025-06-14-14-20-32-741\n",
      "Output.tar.gz location: s3://get-home-safe-216537167580-50a65120/get-home-safe-2025-06-14-14-20-32-741/output/output.tar.gz\n",
      "Intermediate folder path: s3://get-home-safe-216537167580-50a65120/get-home-safe-2025-06-14-14-20-32-741/output/intermediate/\n",
      "Create local folder /tmp/get-home-safe-2025-06-14-14-20-32-741\n"
     ]
    }
   ],
   "source": [
    "job_name = estimator._current_job_name\n",
    "print(\"Job name: {}\".format(job_name))\n",
    "\n",
    "s3_url = \"s3://{}/{}\".format(s3_bucket, job_name)\n",
    "\n",
    "output_tar_key = \"{}/output/output.tar.gz\".format(job_name)\n",
    "\n",
    "intermediate_folder_key = \"{}/output/intermediate/\".format(job_name)\n",
    "output_url = \"s3://{}/{}\".format(s3_bucket, output_tar_key)\n",
    "intermediate_url = \"s3://{}/{}\".format(s3_bucket, intermediate_folder_key)\n",
    "\n",
    "print(\"S3 job path: {}\".format(s3_url))\n",
    "print(\"Output.tar.gz location: {}\".format(output_url))\n",
    "print(\"Intermediate folder path: {}\".format(intermediate_url))\n",
    "\n",
    "tmp_dir = \"/tmp/{}\".format(job_name)\n",
    "os.system(\"mkdir {}\".format(tmp_dir))\n",
    "print(\"Create local folder {}\".format(tmp_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Plot metrics for training job\n",
    "We can pull the reward metric of the training and plot it to see the performance of the model over time.\n",
    "\n",
    "#### Code Cell 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:30:19.880234Z",
     "iopub.status.busy": "2025-06-14T14:30:19.879790Z",
     "iopub.status.idle": "2025-06-14T14:30:24.585975Z",
     "shell.execute_reply": "2025-06-14T14:30:24.585121Z",
     "shell.execute_reply.started": "2025-06-14T14:30:19.880196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:generated new fontManager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for s3://get-home-safe-216537167580-50a65120/get-home-safe-2025-06-14-14-20-32-741/output/intermediate/worker_0.simple_rl_graph.main_level.main_level.agent_0.csv...\n",
      "Downloading get-home-safe-2025-06-14-14-20-32-741/output/intermediate/worker_0.simple_rl_graph.main_level.main_level.agent_0.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_name = \"worker_0.simple_rl_graph.main_level.main_level.agent_0.csv\"\n",
    "key = os.path.join(intermediate_folder_key, csv_file_name)\n",
    "wait_for_s3_object(s3_bucket, key, tmp_dir)\n",
    "\n",
    "csv_file = \"{}/{}\".format(tmp_dir, csv_file_name)\n",
    "df = pd.read_csv(csv_file)\n",
    "df = df.dropna(subset=[\"Training Reward\"])\n",
    "x_axis = \"Episode #\"\n",
    "y_axis = \"Training Reward\"\n",
    "\n",
    "if len(df) > 0:\n",
    "    plt = df.plot(x=x_axis, y=y_axis, figsize=(12, 5), legend=True, style=\"b-\")\n",
    "    plt.set_ylabel(y_axis)\n",
    "    plt.set_xlabel(x_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Visualize the rendered gifs\n",
    "The latest gif file found in the gifs directory is displayed. You can replace the tmp.gif file below to visualize other files generated.\n",
    "\n",
    "#### Code Cell 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:30:29.996012Z",
     "iopub.status.busy": "2025-06-14T14:30:29.995564Z",
     "iopub.status.idle": "2025-06-14T14:30:31.001859Z",
     "shell.execute_reply": "2025-06-14T14:30:31.001049Z",
     "shell.execute_reply.started": "2025-06-14T14:30:29.995978Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for s3://get-home-safe-216537167580-50a65120/get-home-safe-2025-06-14-14-20-32-741/output/intermediate/gifs...\n",
      "Downloading get-home-safe-2025-06-14-14-20-32-741/output/intermediate/gifs/2025-06-14-14-25-33_episode-77_score-92.04621727260404.gif\n",
      "Downloading get-home-safe-2025-06-14-14-20-32-741/output/intermediate/gifs/2025-06-14-14-25-40_episode-78_score-96.9891866049305.gif\n",
      "Downloading get-home-safe-2025-06-14-14-20-32-741/output/intermediate/gifs/2025-06-14-14-28-47_episode-186_score-97.61220127050797.gif\n",
      "Downloading get-home-safe-2025-06-14-14-20-32-741/output/intermediate/gifs/2025-06-14-14-28-50_episode-187_score-98.05955508330175.gif\n",
      "Copied gifs files to /tmp/get-home-safe-2025-06-14-14-20-32-741\n"
     ]
    }
   ],
   "source": [
    "key = os.path.join(intermediate_folder_key, \"gifs\")\n",
    "wait_for_s3_object(s3_bucket, key, tmp_dir)\n",
    "print(\"Copied gifs files to {}\".format(tmp_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:30:35.914836Z",
     "iopub.status.busy": "2025-06-14T14:30:35.914510Z",
     "iopub.status.idle": "2025-06-14T14:30:35.922729Z",
     "shell.execute_reply": "2025-06-14T14:30:35.922031Z",
     "shell.execute_reply.started": "2025-06-14T14:30:35.914812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIFs found:\n",
      "2025-06-14-14-25-33_episode-77_score-92.04621727260404.gif\n",
      "2025-06-14-14-25-40_episode-78_score-96.9891866049305.gif\n",
      "2025-06-14-14-28-47_episode-186_score-97.61220127050797.gif\n",
      "2025-06-14-14-28-50_episode-187_score-98.05955508330175.gif\n"
     ]
    }
   ],
   "source": [
    "glob_pattern = os.path.join(\"{}/*.gif\".format(tmp_dir))\n",
    "gifs = [file for file in glob.iglob(glob_pattern, recursive=True)]\n",
    "extract_episode = lambda string: int(\n",
    "    re.search(\".*episode-(\\d*)_.*\", string, re.IGNORECASE).group(1)\n",
    ")\n",
    "gifs.sort(key=extract_episode)\n",
    "print(\"GIFs found:\\n{}\".format(\"\\n\".join([os.path.basename(gif) for gif in gifs])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:30:39.721089Z",
     "iopub.status.busy": "2025-06-14T14:30:39.720290Z",
     "iopub.status.idle": "2025-06-14T14:30:39.734271Z",
     "shell.execute_reply": "2025-06-14T14:30:39.733428Z",
     "shell.execute_reply.started": "2025-06-14T14:30:39.721056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected GIF: 2025-06-14-14-28-50_episode-187_score-98.05955508330175.gif\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"./src/tmp/2025-06-14-14-28-50_episode-187_score-98.05955508330175.gif.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize a specific episode\n",
    "gif_index = -1  # since you want last gif\n",
    "gif_filepath = gifs[gif_index]\n",
    "gif_filename = os.path.basename(gif_filepath)\n",
    "print(\"Selected GIF: {}\".format(gif_filename))\n",
    "os.system(\"mkdir -p ./src/tmp/ && cp {} ./src/tmp/{}.gif\".format(gif_filepath, gif_filename))\n",
    "HTML('<img src=\"./src/tmp/{}.gif\">'.format(gif_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Model deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you specified MXNet when configuring the RLEstimator, the MXNet deployment container will be used for hosting.\n",
    "\n",
    "#### Code Cell 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:31:10.176704Z",
     "iopub.status.busy": "2025-06-14T14:31:10.176198Z",
     "iopub.status.idle": "2025-06-14T14:33:43.117346Z",
     "shell.execute_reply": "2025-06-14T14:33:43.116428Z",
     "shell.execute_reply.started": "2025-06-14T14:31:10.176667Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-216537167580\n",
      "INFO:sagemaker:Creating model with name: get-home-safe-2025-06-14-14-31-10-178\n",
      "INFO:sagemaker:Creating endpoint-config with name get-home-safe-2025-06-14-14-31-10-178\n",
      "INFO:sagemaker:Creating endpoint with name get-home-safe-2025-06-14-14-31-10-178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m5.large', entry_point=\"deploy-mxnet-coach.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test the endpoint with 2 samples observations. Starting with the car on the right side, but starting to fall back down the hill.\n",
    "\n",
    "#### Code Cell 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predictor.predict(np.array([0.5, -0.5]))\n",
    "action = output[1][0]\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see the policy decides to move the car to the left (negative value). And similarly in the other direction.\n",
    "\n",
    "#### Code Cell 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predictor.predict(np.array([-0.5, 0.5]))\n",
    "action = output[1][0]\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
