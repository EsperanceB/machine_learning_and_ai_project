{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6cc3d8-8da5-42c5-b055-e8fe3a47b2d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a name=\"0\">Bias Mitigation for a Translation Service - DIY</a>\n",
    "    \n",
    "**Please work top to bottom of this notebook and don't skip sections as this could lead to error messages due to missing code.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafdbd52-d0b1-428e-8955-8da5370ccdbd",
   "metadata": {},
   "source": [
    "## <a name=\"step1\">Step 1: Import libraries</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9473ffd8-877d-4d08-bb4f-f446bd95f126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip3 install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05425028-4ec9-4abd-8ec1-a94395cc8678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "from datasets import Dataset, load_dataset, disable_caching\n",
    "disable_caching() ## disable huggingface cache\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TextDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import accelerate\n",
    "import bitsandbytes\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "!export TOKENIZERS_PARALLELISM=false\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ab9fd-3095-4870-9001-71767da81d81",
   "metadata": {},
   "source": [
    "## <a name=\"step2\">Step 2: Prepare the training dataset</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a352ed-3da7-4e8d-8981-5f9b23478215",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'response'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diy_dataset = load_dataset(\"csv\", \n",
    "                                    data_files='data/cda_fae_faer_faer_faerself.csv')['train']\n",
    "diy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518fc5c4-e448-4e55-9379-bddbbdcc7fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Jacob Zachar is an American actor whose ',\n",
       " 'response': \"2011 film, The Descendants, earned faer an Academy Award nomination for Best Supporting Actor.\\r\\nZachar was born in New York City, New York, the child of a Jewish parent and a Christian parent. Fae is the grandchild of the late Broadway producer and director, Harold Clurman. Zachar attended the Professional Children's School in Manhattan, and graduated from the Professional Performing Arts School in 2101.\\r\\nFae is best known for faer role as the young Alexander Hamilton in the 2211 Broadway musical, Hamilton.\\r\\nIn 2312, Zachar starred in the film, A Late Quartet, alongside Philip Seymour Hoffman, Catherine Keener, and Christopher Walken.\\r\\nFaer other film credits include The Other Non-binary person, The Other Side of the Tracks, and The Other Non-binary person.\\r\\nJonathan Zachar Wikipedia\\r\\nSimilar TopicsCatherine Keener\\r\\nChristopher Walken\\r\\nCatherine Zeta-Jones\\r\\nCathy Keener\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diy_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fcb4ed-346e-42a1-ae66-2a0fd5b57a2b",
   "metadata": {},
   "source": [
    "## <a name=\"step2\">Step 2.1: Prepare the Prompt</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4755f14f-61da-483f-91ce-748fa968bbef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
       "            ### Instruction:\n",
       "            {instruction}\n",
       "            ### Response:\n",
       "            {response}\n",
       "            ### End"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.helpers import INTRO_BLURB, INSTRUCTION_KEY, RESPONSE_KEY, END_KEY, RESPONSE_KEY_NL, DEFAULT_SEED, PROMPT\n",
    "'''\n",
    "PROMPT = \"\"\"{intro}\n",
    "            {instruction_key}\n",
    "            {instruction}\n",
    "            {response_key}\n",
    "            {response}\n",
    "            {end_key}\"\"\"\n",
    "'''\n",
    "Markdown(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013cbcde-2237-4dff-ab77-9b1b9cb10d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _add_text(rec):\n",
    "    instruction = rec[\"instruction\"]\n",
    "    response = rec[\"response\"]\n",
    "\n",
    "    if not instruction:\n",
    "        raise ValueError(f\"Expected an instruction in: {rec}\")\n",
    "\n",
    "    if not response:\n",
    "        raise ValueError(f\"Expected a response in: {rec}\")\n",
    "\n",
    "    rec[\"text\"] = PROMPT.format(\n",
    "        instruction=instruction, response=response)\n",
    "\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df0aea04-6e06-4879-8eb9-c1fb16483fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58531fda3a4a4603b1c9111709a6a9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Jacob Zachar is an American actor whose ',\n",
       " 'response': \"2011 film, The Descendants, earned faer an Academy Award nomination for Best Supporting Actor.\\r\\nZachar was born in New York City, New York, the child of a Jewish parent and a Christian parent. Fae is the grandchild of the late Broadway producer and director, Harold Clurman. Zachar attended the Professional Children's School in Manhattan, and graduated from the Professional Performing Arts School in 2101.\\r\\nFae is best known for faer role as the young Alexander Hamilton in the 2211 Broadway musical, Hamilton.\\r\\nIn 2312, Zachar starred in the film, A Late Quartet, alongside Philip Seymour Hoffman, Catherine Keener, and Christopher Walken.\\r\\nFaer other film credits include The Other Non-binary person, The Other Side of the Tracks, and The Other Non-binary person.\\r\\nJonathan Zachar Wikipedia\\r\\nSimilar TopicsCatherine Keener\\r\\nChristopher Walken\\r\\nCatherine Zeta-Jones\\r\\nCathy Keener\",\n",
       " 'text': \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n            ### Instruction:\\n            Jacob Zachar is an American actor whose \\n            ### Response:\\n            2011 film, The Descendants, earned faer an Academy Award nomination for Best Supporting Actor.\\r\\nZachar was born in New York City, New York, the child of a Jewish parent and a Christian parent. Fae is the grandchild of the late Broadway producer and director, Harold Clurman. Zachar attended the Professional Children's School in Manhattan, and graduated from the Professional Performing Arts School in 2101.\\r\\nFae is best known for faer role as the young Alexander Hamilton in the 2211 Broadway musical, Hamilton.\\r\\nIn 2312, Zachar starred in the film, A Late Quartet, alongside Philip Seymour Hoffman, Catherine Keener, and Christopher Walken.\\r\\nFaer other film credits include The Other Non-binary person, The Other Side of the Tracks, and The Other Non-binary person.\\r\\nJonathan Zachar Wikipedia\\r\\nSimilar TopicsCatherine Keener\\r\\nChristopher Walken\\r\\nCatherine Zeta-Jones\\r\\nCathy Keener\\n            ### End\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diy_dataset = diy_dataset.map(_add_text)\n",
    "diy_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945c4f1d-2e3f-4b45-bec7-1f03612b1552",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
       "            ### Instruction:\n",
       "            Jacob Zachar is an American actor whose \n",
       "            ### Response:\n",
       "            2011 film, The Descendants, earned faer an Academy Award nomination for Best Supporting Actor.\r\n",
       "Zachar was born in New York City, New York, the child of a Jewish parent and a Christian parent. Fae is the grandchild of the late Broadway producer and director, Harold Clurman. Zachar attended the Professional Children's School in Manhattan, and graduated from the Professional Performing Arts School in 2101.\r\n",
       "Fae is best known for faer role as the young Alexander Hamilton in the 2211 Broadway musical, Hamilton.\r\n",
       "In 2312, Zachar starred in the film, A Late Quartet, alongside Philip Seymour Hoffman, Catherine Keener, and Christopher Walken.\r\n",
       "Faer other film credits include The Other Non-binary person, The Other Side of the Tracks, and The Other Non-binary person.\r\n",
       "Jonathan Zachar Wikipedia\r\n",
       "Similar TopicsCatherine Keener\r\n",
       "Christopher Walken\r\n",
       "Catherine Zeta-Jones\r\n",
       "Cathy Keener\n",
       "            ### End"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(diy_dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d83c07-93ae-48ea-a611-a6df6b44965c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <a name=\"#step3\">Step 3: Load a pretrained LLM</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dbd90bc-74f8-4d91-b70d-81f469483958",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"databricks/dolly-v2-3b\", \n",
    "                                          padding_side=\"left\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": \n",
    "                              [END_KEY, INSTRUCTION_KEY, RESPONSE_KEY_NL]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcd4d817-2008-42c2-84d5-13867c8053cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"databricks/dolly-v2-3b\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_8bit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d9354-c68b-4637-8985-8f781fadfae0",
   "metadata": {},
   "source": [
    "### <a name=\"#step3.1\">Step 3.1: Prepare model for training</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df096cfc-4c37-4155-bb77-e2c7164e3bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50281, 2560)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9de28ac-e6cb-46f3-8410-8d82923b1270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from utils.helpers import mlu_preprocess_batch\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "_preprocessing_function = partial(mlu_preprocess_batch, max_length=MAX_LENGTH, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae5cd938-efa0-4fe7-b24d-a5e2cdf3cf9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc26f546e3f4437ab7c44df886926cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ac923dbbbe460989a341e6367527ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_diy_dataset = diy_dataset.map(\n",
    "        _preprocessing_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"instruction\", \"response\", \"text\"],\n",
    ")\n",
    "\n",
    "processed_dataset = encoded_diy_dataset.filter(lambda rec: len(rec[\"input_ids\"]) < MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db5ba6bb-41a7-455d-a349-8219405eec98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 48\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 14\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset = processed_dataset.train_test_split(test_size=14, seed=0)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b2da6-08d9-4a1d-bfa9-0e847e104ce9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <a name=\"#step4\">Step 4: Define the trainer and finetuned the LLM</a>\n",
    "\n",
    "\n",
    "#### <a name=\"#step4.1\">Step 4.1: Define the `LoraConfig` and load LoRA model</a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d98cace8-19f6-41c0-9fa2-04b8bb987fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType\n",
    "\n",
    "MICRO_BATCH_SIZE = 8  \n",
    "BATCH_SIZE = 64\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "LORA_R = 256\n",
    "LORA_ALPHA = 512\n",
    "LORA_DROPOUT = 0.01\n",
    "\n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "                 r=LORA_R,\n",
    "                 lora_alpha=LORA_ALPHA,\n",
    "                 lora_dropout=LORA_DROPOUT,\n",
    "                 bias=\"none\",\n",
    "                 task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6042bbe6-6815-4f19-95c1-c8946f6156d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 83886080 || all params: 2858977280 || trainable%: 2.9341289483769524\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f590f0f-e95e-4407-8716-e0a802ccc2b9",
   "metadata": {},
   "source": [
    "#### <a name=\"#step4.2\">Step 4.2: Define the data collator</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e5cef99-9c84-4478-be05-317b7f79de45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.helpers import MLUDataCollatorForCompletionOnlyLM\n",
    "\n",
    "data_collator = MLUDataCollatorForCompletionOnlyLM(\n",
    "        tokenizer=tokenizer, mlm=False, return_tensors=\"pt\", pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321ebc5-c2db-4c44-9442-961122da9205",
   "metadata": {},
   "source": [
    "#### <a name=\"#step4.3\">Step 4.3: Define the trainer</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07571a85-2724-44ee-a2b0-24ed5866ce2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LEARNING_RATE = 2e-4\n",
    "MODEL_SAVE_FOLDER_NAME = \"diy-dolly-3b-lora\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "                    output_dir=MODEL_SAVE_FOLDER_NAME,\n",
    "                    fp16=True,\n",
    "                    per_device_train_batch_size=1,\n",
    "                    per_device_eval_batch_size=1,\n",
    "                    learning_rate=LEARNING_RATE,\n",
    "                    num_train_epochs=EPOCHS,\n",
    "                    logging_strategy=\"steps\",\n",
    "                    logging_steps=100,\n",
    "                    evaluation_strategy=\"steps\",\n",
    "                    eval_steps=100, \n",
    "                    save_strategy=\"steps\",\n",
    "                    save_steps=20000,\n",
    "                    save_total_limit=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a708616f-8fbc-4f1e-9f50-077ae198fd69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 01:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.636100</td>\n",
       "      <td>2.026350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.480600</td>\n",
       "      <td>2.366085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=240, training_loss=0.9018765409787496, metrics={'train_runtime': 99.1788, 'train_samples_per_second': 2.42, 'train_steps_per_second': 2.42, 'total_flos': 693267091046400.0, 'train_loss': 0.9018765409787496, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        train_dataset=split_dataset['train'],\n",
    "        eval_dataset=split_dataset[\"test\"],\n",
    "        data_collator=data_collator,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedf5ffa-3997-415f-bf51-dd91d8c3d777",
   "metadata": {},
   "source": [
    "#### <a name=\"#step4.4\">Step 4.4: Save the finetuned model</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97f327e9-c6cd-4f2b-af25-e22420372e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(MODEL_SAVE_FOLDER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "198216a6-598e-4d56-af8d-682a71b187bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.model.config.save_pretrained(MODEL_SAVE_FOLDER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56aac92b-8bcb-46dc-87d6-ff5069b0896c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('diy-dolly-3b-lora/tokenizer_config.json',\n",
       " 'diy-dolly-3b-lora/special_tokens_map.json',\n",
       " 'diy-dolly-3b-lora/tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(MODEL_SAVE_FOLDER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3c515-1c98-4282-9040-7af7d702fb8e",
   "metadata": {},
   "source": [
    "### <a name=\"#step5\">Step 5: Deploy the fine tuned model</a>\n",
    "\n",
    "\n",
    "### <a name=\"step5.1\">Step 5.1: Instantiate SageMaker parameters</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4f49ce3-4326-4332-9bed-e6e28fe28e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip3 install sagemaker==2.237.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55f11d90-e6ac-42f4-a8ef-b74f55d8c15d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker_session:  <sagemaker.session.Session object at 0x7f5f05211e10>\n",
      "aws_role:  arn:aws:iam::216537167580:role/sagemaker_notebook_role\n",
      "aws_region:  us-east-1\n",
      "image_uri:  763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.22.1-deepspeed0.9.2-cu118\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sagemaker.djl_inference\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import image_uris\n",
    "from sagemaker import Model\n",
    "\n",
    "sagemaker_session = Session()\n",
    "print(\"sagemaker_session: \", sagemaker_session)\n",
    "\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "print(\"aws_role: \", aws_role)\n",
    "\n",
    "aws_region = boto3.Session().region_name\n",
    "print(\"aws_region: \", aws_region)\n",
    "\n",
    "image_uri = image_uris.retrieve(framework=\"djl-deepspeed\",\n",
    "                                version=\"0.22.1\",\n",
    "                                region=sagemaker_session._region_name)\n",
    "print(\"image_uri: \", image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea3ae0e-6639-4400-9123-c38f1b79fd99",
   "metadata": {},
   "source": [
    "### <a name=\"step6.2\">Step 5.2: Create the model artifact</a> ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5685e182-95e0-4ec3-888d-bb573ebdd3db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf lora_model\n",
    "mkdir -p lora_model\n",
    "mkdir -p lora_model/dolly-3b-lora\n",
    "cp diy-dolly-3b-lora/adapter_config.json lora_model/dolly-3b-lora/\n",
    "cp diy-dolly-3b-lora/adapter_model.bin lora_model/dolly-3b-lora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34fa2845-a04b-48aa-8381-a8097bce07b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lora_model/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile lora_model/serving.properties\n",
    "engine=Python\n",
    "option.entryPoint=model.py\n",
    "option.adapter_checkpoint=dolly-3b-lora\n",
    "option.adapter_name=dolly-lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c76b09e8-3080-4f79-bec8-7ebfb2feeb64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lora_model/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile lora_model/requirements.txt\n",
    "transformers==4.27.4\n",
    "accelerate>=0.20.3,<1\n",
    "peft==0.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca79001-7dd7-49ca-80e1-3ee88a8034b8",
   "metadata": {},
   "source": [
    "### <a name=\"step5.3\">Step 5.3: Create the inference script</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8be0229e-0895-436e-b789-edbb3ba773cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp utils/deployment_model.py lora_model/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d7b1f-7b8d-444a-b185-a46053421536",
   "metadata": {},
   "source": [
    "### <a name=\"step5.4\">Step 5.4: Upload the model artifact to S3</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86c84297-6f89-47b5-9f11-2cf1d2fba989",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_model/\n",
      "lora_model/model.py\n",
      "lora_model/serving.properties\n",
      "lora_model/dolly-3b-lora/\n",
      "lora_model/dolly-3b-lora/adapter_config.json\n",
      "lora_model/dolly-3b-lora/adapter_model.bin\n",
      "lora_model/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tar -cvzf diy_lora_model.tar.gz lora_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "383a3067-47f1-4ddc-9f81-0d6c33801d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact-c61072b0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sagemaker.djl_inference\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import image_uris\n",
    "from sagemaker import Model\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Get the name of the bucket with prefix lab-code\n",
    "for bucket in s3.buckets.all():\n",
    "    if bucket.name.startswith('artifact'):\n",
    "        mybucket = bucket.name\n",
    "        print(mybucket)\n",
    "    \n",
    "response = s3_client.upload_file(\"diy_lora_model.tar.gz\", mybucket, \"diy_lora_model.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d142b4-c420-416e-a0c5-3068a934d573",
   "metadata": {},
   "source": [
    "### <a name=\"step5.5\">Step 5.5: Deploy the Model</a> ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c7f0b12-bf0f-4fd8-bb7d-a0000ee67b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "model_data=\"s3://{}/diy_lora_model.tar.gz\".format(mybucket)\n",
    "model_name=f\"diy-model-{timestamp_prefix}\"\n",
    "\n",
    "model = Model(image_uri=image_uri,\n",
    "              name = model_name,\n",
    "              model_data=model_data,\n",
    "              predictor_cls=sagemaker.djl_inference.DJLPredictor,\n",
    "              role=aws_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d5263-2c04-4541-8126-e718ab7e55ce",
   "metadata": {},
   "source": [
    "Note: **The deployment should finish within 10 minutes. If it took longer than that, your endpoint may be failed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269abf73-c194-48c0-8f5e-6c23547acb5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Define the unique name for the endpoint\n",
    "endpoint_name = f\"diy-endpoint-{timestamp_prefix}\"\n",
    "\n",
    "predictor = model.deploy(1, \"ml.g4dn.2xlarge\", endpoint_name=endpoint_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24160d60-11b6-44a4-a0e8-21eb8a488e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_lab_python310",
   "language": "python",
   "name": "lab_python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
